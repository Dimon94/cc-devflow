# ä¸€è‡´æ€§æ£€æŸ¥å†²çªæ£€æµ‹ç®—æ³•è®¾è®¡

> **è®¾è®¡ç›®æ ‡**: å»ºç«‹æ™ºèƒ½çš„å†²çªæ£€æµ‹å’Œè§£å†³æœºåˆ¶
> **åˆ›å»ºæ—¶é—´**: 2025-01-20
> **ç‰ˆæœ¬**: v1.0

## ğŸ“‹ æ¦‚è¿°

ä¸º cc-devflow çš„ä¸€è‡´æ€§æ£€æŸ¥ç³»ç»Ÿè®¾è®¡é«˜æ•ˆçš„å†²çªæ£€æµ‹ç®—æ³•ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«æ–‡æ¡£é—´çš„å†²çªã€éœ€æ±‚çš„çŸ›ç›¾ä»¥åŠå®ç°çš„åå·®ï¼Œå¹¶æä¾›æ™ºèƒ½çš„è§£å†³å»ºè®®ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

### æ£€æµ‹èƒ½åŠ›
1. **è¯­ä¹‰å†²çªæ£€æµ‹**: è¯†åˆ«è¡¨è¾¾ä¸åŒä½†å«ä¹‰å†²çªçš„éœ€æ±‚
2. **é€»è¾‘çŸ›ç›¾å‘ç°**: å‘ç°ä¸šåŠ¡è§„åˆ™å’ŒæŠ€æœ¯çº¦æŸé—´çš„çŸ›ç›¾
3. **å®ç°åå·®è¯†åˆ«**: æ£€æµ‹ä»£ç å®ç°ä¸è§„æ ¼è¯´æ˜çš„åå·®
4. **ç‰ˆæœ¬ä¸ä¸€è‡´æ€§**: å‘ç°æ–‡æ¡£é—´çš„ç‰ˆæœ¬åŒæ­¥é—®é¢˜

### ç®—æ³•ç‰¹æ€§
- **å‡†ç¡®æ€§**: å‡å°‘è¯¯æŠ¥ï¼Œæé«˜æ£€æµ‹ç²¾åº¦
- **æ•ˆç‡æ€§**: æ”¯æŒå¤§è§„æ¨¡é¡¹ç›®çš„å¿«é€Ÿæ£€æŸ¥
- **å¯æ‰©å±•æ€§**: æ”¯æŒè‡ªå®šä¹‰è§„åˆ™å’Œæ–°çš„æ£€æµ‹ç»´åº¦
- **æ™ºèƒ½æ€§**: åŸºäºä¸Šä¸‹æ–‡ç†è§£è¿›è¡Œæ™ºèƒ½åˆ¤æ–­

## ğŸ— ç®—æ³•æ¶æ„

### æ•´ä½“æ¡†æ¶
```yaml
å†²çªæ£€æµ‹æµæ°´çº¿:
  1. æ•°æ®é¢„å¤„ç†: æ–‡æ¡£è§£æå’Œç»“æ„åŒ–
  2. ç‰¹å¾æå–: å…³é”®ä¿¡æ¯è¯†åˆ«å’ŒæŠ½å–
  3. å†²çªåˆ†æ: å¤šç»´åº¦å†²çªæ£€æµ‹
  4. ç»“æœè¯„åˆ†: å†²çªä¸¥é‡ç¨‹åº¦è¯„ä¼°
  5. è§£å†³å»ºè®®: æ™ºèƒ½ä¿®å¤æ–¹æ¡ˆç”Ÿæˆ

ç®—æ³•åˆ†å±‚:
  è¯­æ³•å±‚: æ ¼å¼å’Œç»“æ„å†²çª
  è¯­ä¹‰å±‚: å«ä¹‰å’Œé€»è¾‘å†²çª
  å®ç°å±‚: ä»£ç å’Œè§„æ ¼å†²çª
  ä¸šåŠ¡å±‚: éœ€æ±‚å’Œçº¦æŸå†²çª
```

## ğŸ” æ ¸å¿ƒæ£€æµ‹ç®—æ³•

### 1. è¯­ä¹‰å†²çªæ£€æµ‹ç®—æ³•

#### 1.1 éœ€æ±‚æè¿°çŸ›ç›¾æ£€æµ‹
```python
class RequirementConflictDetector:
    def __init__(self):
        self.semantic_analyzer = SemanticAnalyzer()
        self.conflict_patterns = ConflictPatternLibrary()

    def detect_semantic_conflicts(self, requirements: List[Requirement]) -> List[Conflict]:
        """
        æ£€æµ‹éœ€æ±‚é—´çš„è¯­ä¹‰å†²çª
        """
        conflicts = []

        # 1. æ„å»ºè¯­ä¹‰å‘é‡ç©ºé—´
        semantic_vectors = self.build_semantic_vectors(requirements)

        # 2. è¯†åˆ«ç›¸ä¼¼ä½†çŸ›ç›¾çš„éœ€æ±‚
        for i, req_a in enumerate(requirements):
            for j, req_b in enumerate(requirements[i+1:], i+1):
                similarity = self.calculate_semantic_similarity(
                    semantic_vectors[i], semantic_vectors[j]
                )

                # é«˜ç›¸ä¼¼åº¦ä½†é€»è¾‘çŸ›ç›¾
                if similarity > 0.7 and self.is_logically_contradictory(req_a, req_b):
                    conflict = self.create_semantic_conflict(req_a, req_b, similarity)
                    conflicts.append(conflict)

        return conflicts

    def is_logically_contradictory(self, req_a: Requirement, req_b: Requirement) -> bool:
        """
        æ£€æµ‹ä¸¤ä¸ªéœ€æ±‚æ˜¯å¦å­˜åœ¨é€»è¾‘çŸ›ç›¾
        """
        # æå–åŠ¨ä½œå’Œçº¦æŸ
        actions_a = self.extract_actions(req_a)
        constraints_a = self.extract_constraints(req_a)

        actions_b = self.extract_actions(req_b)
        constraints_b = self.extract_constraints(req_b)

        # æ£€æµ‹çŸ›ç›¾æ¨¡å¼
        contradictory_patterns = [
            self.check_exclusive_actions(actions_a, actions_b),
            self.check_conflicting_constraints(constraints_a, constraints_b),
            self.check_temporal_conflicts(req_a, req_b),
            self.check_access_control_conflicts(req_a, req_b)
        ]

        return any(contradictory_patterns)
```

#### 1.2 ä¸šåŠ¡è§„åˆ™å†²çªæ£€æµ‹
```python
class BusinessRuleConflictDetector:
    def __init__(self):
        self.rule_parser = BusinessRuleParser()
        self.logic_engine = LogicInferenceEngine()

    def detect_rule_conflicts(self, business_rules: List[BusinessRule]) -> List[RuleConflict]:
        """
        æ£€æµ‹ä¸šåŠ¡è§„åˆ™é—´çš„å†²çª
        """
        conflicts = []

        # 1. è§£æä¸šåŠ¡è§„åˆ™ä¸ºé€»è¾‘è¡¨è¾¾å¼
        logical_rules = [self.rule_parser.parse(rule) for rule in business_rules]

        # 2. æ„å»ºè§„åˆ™ä¾èµ–å›¾
        dependency_graph = self.build_rule_dependency_graph(logical_rules)

        # 3. æ£€æµ‹å¾ªç¯ä¾èµ–
        cycles = self.detect_circular_dependencies(dependency_graph)
        for cycle in cycles:
            conflicts.append(CircularDependencyConflict(cycle))

        # 4. æ£€æµ‹é€»è¾‘çŸ›ç›¾
        for rule_set in self.generate_rule_combinations(logical_rules):
            if not self.logic_engine.is_satisfiable(rule_set):
                conflicts.append(LogicalContradictionConflict(rule_set))

        return conflicts

    def generate_rule_combinations(self, rules: List[LogicalRule]) -> Iterator[List[LogicalRule]]:
        """
        ç”Ÿæˆå¯èƒ½äº§ç”Ÿå†²çªçš„è§„åˆ™ç»„åˆ
        """
        # åŸºäºè§„åˆ™å¤æ‚åº¦å’Œç›¸å…³æ€§çš„æ™ºèƒ½ç»„åˆç”Ÿæˆ
        for size in range(2, min(len(rules) + 1, MAX_COMBINATION_SIZE)):
            for combination in itertools.combinations(rules, size):
                if self.is_potentially_conflicting(combination):
                    yield list(combination)
```

### 2. å®ç°åå·®æ£€æµ‹ç®—æ³•

#### 2.1 API è§„æ ¼ä¸€è‡´æ€§æ£€æµ‹
```python
class APIConsistencyDetector:
    def __init__(self):
        self.spec_parser = APISpecParser()
        self.code_analyzer = CodeAnalyzer()

    def detect_api_inconsistencies(self,
                                   api_spec: APISpecification,
                                   implementation: CodeBase) -> List[APIInconsistency]:
        """
        æ£€æµ‹ API è§„æ ¼ä¸å®ç°çš„ä¸ä¸€è‡´
        """
        inconsistencies = []

        # 1. è§£æ API è§„æ ¼
        spec_endpoints = self.spec_parser.extract_endpoints(api_spec)

        # 2. åˆ†æå®ç°ä»£ç 
        impl_endpoints = self.code_analyzer.extract_endpoints(implementation)

        # 3. æ£€æµ‹å„ç§ä¸ä¸€è‡´ç±»å‹
        inconsistencies.extend(self.detect_missing_endpoints(spec_endpoints, impl_endpoints))
        inconsistencies.extend(self.detect_extra_endpoints(spec_endpoints, impl_endpoints))
        inconsistencies.extend(self.detect_signature_mismatches(spec_endpoints, impl_endpoints))
        inconsistencies.extend(self.detect_response_format_mismatches(spec_endpoints, impl_endpoints))

        return inconsistencies

    def detect_signature_mismatches(self,
                                   spec_endpoints: List[EndpointSpec],
                                   impl_endpoints: List[EndpointImpl]) -> List[SignatureMismatch]:
        """
        æ£€æµ‹æ–¹æ³•ç­¾åä¸åŒ¹é…
        """
        mismatches = []

        for spec_endpoint in spec_endpoints:
            impl_endpoint = self.find_matching_endpoint(spec_endpoint, impl_endpoints)
            if impl_endpoint:
                # æ£€æµ‹å‚æ•°ä¸åŒ¹é…
                param_mismatches = self.compare_parameters(
                    spec_endpoint.parameters,
                    impl_endpoint.parameters
                )

                # æ£€æµ‹è¿”å›ç±»å‹ä¸åŒ¹é…
                return_mismatches = self.compare_return_types(
                    spec_endpoint.return_type,
                    impl_endpoint.return_type
                )

                if param_mismatches or return_mismatches:
                    mismatch = SignatureMismatch(
                        endpoint=spec_endpoint.path,
                        parameter_issues=param_mismatches,
                        return_type_issues=return_mismatches
                    )
                    mismatches.append(mismatch)

        return mismatches
```

#### 2.2 æ•°æ®æ¨¡å‹ä¸€è‡´æ€§æ£€æµ‹
```python
class DataModelConsistencyDetector:
    def __init__(self):
        self.schema_analyzer = SchemaAnalyzer()
        self.field_matcher = FieldMatcher()

    def detect_model_inconsistencies(self,
                                    specification_models: List[DataModel],
                                    implementation_models: List[DataModel]) -> List[ModelInconsistency]:
        """
        æ£€æµ‹æ•°æ®æ¨¡å‹çš„ä¸ä¸€è‡´æ€§
        """
        inconsistencies = []

        # 1. å»ºç«‹æ¨¡å‹æ˜ å°„å…³ç³»
        model_mappings = self.establish_model_mappings(specification_models, implementation_models)

        # 2. æ£€æµ‹å„ç§ä¸ä¸€è‡´ç±»å‹
        for spec_model, impl_model in model_mappings:
            inconsistencies.extend(self.check_field_consistency(spec_model, impl_model))
            inconsistencies.extend(self.check_relationship_consistency(spec_model, impl_model))
            inconsistencies.extend(self.check_constraint_consistency(spec_model, impl_model))
            inconsistencies.extend(self.check_validation_consistency(spec_model, impl_model))

        # 3. æ£€æµ‹å­¤ç«‹æ¨¡å‹
        inconsistencies.extend(self.detect_orphaned_models(specification_models, implementation_models))

        return inconsistencies

    def check_field_consistency(self, spec_model: DataModel, impl_model: DataModel) -> List[FieldInconsistency]:
        """
        æ£€æµ‹å­—æ®µçº§åˆ«çš„ä¸ä¸€è‡´æ€§
        """
        inconsistencies = []

        spec_fields = {field.name: field for field in spec_model.fields}
        impl_fields = {field.name: field for field in impl_model.fields}

        # æ£€æµ‹ç¼ºå¤±å­—æ®µ
        missing_fields = set(spec_fields.keys()) - set(impl_fields.keys())
        for field_name in missing_fields:
            inconsistencies.append(MissingFieldInconsistency(
                model=spec_model.name,
                field=field_name,
                specification=spec_fields[field_name]
            ))

        # æ£€æµ‹é¢å¤–å­—æ®µ
        extra_fields = set(impl_fields.keys()) - set(spec_fields.keys())
        for field_name in extra_fields:
            inconsistencies.append(ExtraFieldInconsistency(
                model=impl_model.name,
                field=field_name,
                implementation=impl_fields[field_name]
            ))

        # æ£€æµ‹å­—æ®µç±»å‹ä¸åŒ¹é…
        common_fields = set(spec_fields.keys()) & set(impl_fields.keys())
        for field_name in common_fields:
            spec_field = spec_fields[field_name]
            impl_field = impl_fields[field_name]

            if not self.are_types_compatible(spec_field.type, impl_field.type):
                inconsistencies.append(FieldTypeMismatchInconsistency(
                    model=spec_model.name,
                    field=field_name,
                    spec_type=spec_field.type,
                    impl_type=impl_field.type
                ))

        return inconsistencies
```

### 3. ç‰ˆæœ¬ä¸ä¸€è‡´æ€§æ£€æµ‹ç®—æ³•

#### 3.1 æ–‡æ¡£ç‰ˆæœ¬åŒæ­¥æ£€æµ‹
```python
class DocumentVersionConsistencyDetector:
    def __init__(self):
        self.version_extractor = VersionExtractor()
        self.dependency_analyzer = DocumentDependencyAnalyzer()

    def detect_version_inconsistencies(self, documents: List[Document]) -> List[VersionInconsistency]:
        """
        æ£€æµ‹æ–‡æ¡£é—´çš„ç‰ˆæœ¬ä¸ä¸€è‡´æ€§
        """
        inconsistencies = []

        # 1. æå–æ‰€æœ‰æ–‡æ¡£çš„ç‰ˆæœ¬ä¿¡æ¯
        document_versions = self.extract_all_versions(documents)

        # 2. æ„å»ºæ–‡æ¡£ä¾èµ–å…³ç³»å›¾
        dependency_graph = self.dependency_analyzer.build_dependency_graph(documents)

        # 3. æ£€æµ‹ç‰ˆæœ¬ä¸å…¼å®¹
        for doc_a, doc_b in dependency_graph.edges():
            version_a = document_versions[doc_a.id]
            version_b = document_versions[doc_b.id]

            if not self.are_versions_compatible(version_a, version_b, dependency_graph.get_edge_data(doc_a, doc_b)):
                inconsistency = VersionIncompatibilityInconsistency(
                    source_document=doc_a,
                    target_document=doc_b,
                    source_version=version_a,
                    target_version=version_b,
                    dependency_type=dependency_graph.get_edge_data(doc_a, doc_b)['type']
                )
                inconsistencies.append(inconsistency)

        return inconsistencies

    def are_versions_compatible(self, version_a: Version, version_b: Version, dependency_info: Dict) -> bool:
        """
        æ£€æŸ¥ä¸¤ä¸ªç‰ˆæœ¬æ˜¯å¦å…¼å®¹
        """
        dependency_type = dependency_info.get('type', 'reference')

        if dependency_type == 'strict_dependency':
            # ä¸¥æ ¼ä¾èµ–è¦æ±‚ç²¾ç¡®ç‰ˆæœ¬åŒ¹é…
            return version_a == version_b
        elif dependency_type == 'compatible_dependency':
            # å…¼å®¹ä¾èµ–å…è®¸å‘åå…¼å®¹çš„ç‰ˆæœ¬
            return version_a.is_compatible_with(version_b)
        else:
            # ä¸€èˆ¬å¼•ç”¨å…è®¸è¾ƒå¤§çš„ç‰ˆæœ¬å·®å¼‚
            return version_a.major == version_b.major
```

### 4. æ™ºèƒ½å†²çªè§£å†³ç®—æ³•

#### 4.1 å†²çªä¼˜å…ˆçº§è¯„ä¼°
```python
class ConflictPriorityEvaluator:
    def __init__(self):
        self.impact_analyzer = ImpactAnalyzer()
        self.complexity_evaluator = ComplexityEvaluator()

    def evaluate_conflict_priority(self, conflict: Conflict) -> ConflictPriority:
        """
        è¯„ä¼°å†²çªçš„è§£å†³ä¼˜å…ˆçº§
        """
        # 1. å½±å“åˆ†æ
        business_impact = self.impact_analyzer.assess_business_impact(conflict)
        technical_impact = self.impact_analyzer.assess_technical_impact(conflict)
        user_impact = self.impact_analyzer.assess_user_impact(conflict)

        # 2. å¤æ‚åº¦è¯„ä¼°
        resolution_complexity = self.complexity_evaluator.assess_resolution_complexity(conflict)

        # 3. é£é™©è¯„ä¼°
        risk_level = self.assess_risk_level(conflict)

        # 4. è®¡ç®—ç»¼åˆä¼˜å…ˆçº§åˆ†æ•°
        priority_score = self.calculate_priority_score(
            business_impact=business_impact,
            technical_impact=technical_impact,
            user_impact=user_impact,
            resolution_complexity=resolution_complexity,
            risk_level=risk_level
        )

        return ConflictPriority(
            score=priority_score,
            level=self.score_to_level(priority_score),
            rationale=self.generate_priority_rationale(conflict, priority_score)
        )

    def calculate_priority_score(self, **factors) -> float:
        """
        åŸºäºå¤šä¸ªå› ç´ è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°
        """
        weights = {
            'business_impact': 0.3,
            'technical_impact': 0.25,
            'user_impact': 0.2,
            'resolution_complexity': -0.15,  # å¤æ‚åº¦è¶Šé«˜ï¼Œä¼˜å…ˆçº§è¶Šä½
            'risk_level': 0.2
        }

        weighted_score = sum(
            factors[factor] * weight
            for factor, weight in weights.items()
            if factor in factors
        )

        return min(max(weighted_score, 0.0), 1.0)  # å½’ä¸€åŒ–åˆ° [0, 1]
```

#### 4.2 è‡ªåŠ¨è§£å†³æ–¹æ¡ˆç”Ÿæˆ
```python
class AutoResolutionGenerator:
    def __init__(self):
        self.resolution_strategies = ResolutionStrategyLibrary()
        self.feasibility_checker = FeasibilityChecker()

    def generate_resolution_options(self, conflict: Conflict) -> List[ResolutionOption]:
        """
        ä¸ºå†²çªç”Ÿæˆå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
        """
        options = []

        # 1. åŸºäºå†²çªç±»å‹è·å–å€™é€‰ç­–ç•¥
        candidate_strategies = self.resolution_strategies.get_strategies_for_conflict_type(conflict.type)

        # 2. ä¸ºæ¯ä¸ªç­–ç•¥ç”Ÿæˆå…·ä½“çš„è§£å†³æ–¹æ¡ˆ
        for strategy in candidate_strategies:
            resolution_option = self.generate_resolution_from_strategy(conflict, strategy)

            # 3. è¯„ä¼°å¯è¡Œæ€§
            feasibility = self.feasibility_checker.assess_feasibility(resolution_option)

            if feasibility.is_feasible:
                resolution_option.feasibility = feasibility
                options.append(resolution_option)

        # 4. æŒ‰é¢„æœŸæ•ˆæœæ’åº
        options.sort(key=lambda opt: opt.expected_effectiveness, reverse=True)

        return options

    def generate_resolution_from_strategy(self, conflict: Conflict, strategy: ResolutionStrategy) -> ResolutionOption:
        """
        åŸºäºç­–ç•¥ç”Ÿæˆå…·ä½“çš„è§£å†³æ–¹æ¡ˆ
        """
        if strategy.type == "merge_conflicting_requirements":
            return self.generate_merge_solution(conflict, strategy)
        elif strategy.type == "prioritize_and_exclude":
            return self.generate_prioritization_solution(conflict, strategy)
        elif strategy.type == "introduce_conditional_logic":
            return self.generate_conditional_solution(conflict, strategy)
        elif strategy.type == "refactor_architecture":
            return self.generate_refactoring_solution(conflict, strategy)
        else:
            return self.generate_generic_solution(conflict, strategy)
```

## ğŸ“Š ç®—æ³•æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†ä¼˜åŒ–
```python
class ParallelConflictDetector:
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or cpu_count()
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)

    def detect_conflicts_parallel(self, documents: List[Document]) -> List[Conflict]:
        """
        å¹¶è¡Œæ‰§è¡Œå†²çªæ£€æµ‹
        """
        # 1. å°†æ–‡æ¡£åˆ†ç»„ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        document_groups = self.partition_documents(documents)

        # 2. å¹¶è¡Œæ£€æµ‹æ¯ç»„å†…çš„å†²çª
        intra_group_futures = [
            self.executor.submit(self.detect_intra_group_conflicts, group)
            for group in document_groups
        ]

        # 3. å¹¶è¡Œæ£€æµ‹ç»„é—´å†²çª
        inter_group_futures = [
            self.executor.submit(self.detect_inter_group_conflicts, group_a, group_b)
            for group_a, group_b in itertools.combinations(document_groups, 2)
        ]

        # 4. æ”¶é›†ç»“æœ
        all_conflicts = []
        for future in concurrent.futures.as_completed(intra_group_futures + inter_group_futures):
            all_conflicts.extend(future.result())

        return all_conflicts
```

### 2. ç¼“å­˜å’Œå¢é‡æ£€æµ‹
```python
class IncrementalConflictDetector:
    def __init__(self):
        self.cache = ConflictDetectionCache()
        self.change_tracker = DocumentChangeTracker()

    def detect_conflicts_incremental(self,
                                   documents: List[Document],
                                   last_check_timestamp: datetime) -> List[Conflict]:
        """
        å¢é‡å†²çªæ£€æµ‹
        """
        # 1. è¯†åˆ«è‡ªä¸Šæ¬¡æ£€æŸ¥ä»¥æ¥çš„å˜æ›´
        changed_documents = self.change_tracker.get_changed_documents(last_check_timestamp)

        # 2. ä»ç¼“å­˜ä¸­è·å–æœªå˜æ›´æ–‡æ¡£çš„æ£€æµ‹ç»“æœ
        cached_conflicts = self.cache.get_conflicts_for_unchanged_documents(
            set(documents) - set(changed_documents)
        )

        # 3. åªå¯¹å˜æ›´çš„æ–‡æ¡£åŠå…¶ä¾èµ–æ–‡æ¡£è¿›è¡Œé‡æ–°æ£€æµ‹
        affected_documents = self.get_affected_documents(changed_documents, documents)
        new_conflicts = self.detect_conflicts_for_documents(affected_documents)

        # 4. æ›´æ–°ç¼“å­˜
        self.cache.update_conflicts(affected_documents, new_conflicts)

        return cached_conflicts + new_conflicts
```

## ğŸ¯ è´¨é‡ä¿è¯

### ç®—æ³•æµ‹è¯•æ¡†æ¶
```python
class ConflictDetectionTestSuite:
    def __init__(self):
        self.test_data_generator = TestDataGenerator()
        self.ground_truth_validator = GroundTruthValidator()

    def run_comprehensive_tests(self):
        """
        è¿è¡Œå…¨é¢çš„ç®—æ³•æµ‹è¯•
        """
        test_results = TestResults()

        # 1. å‡†ç¡®æ€§æµ‹è¯•
        accuracy_results = self.test_detection_accuracy()
        test_results.add_accuracy_results(accuracy_results)

        # 2. æ€§èƒ½æµ‹è¯•
        performance_results = self.test_performance()
        test_results.add_performance_results(performance_results)

        # 3. é²æ£’æ€§æµ‹è¯•
        robustness_results = self.test_robustness()
        test_results.add_robustness_results(robustness_results)

        # 4. å¯æ‰©å±•æ€§æµ‹è¯•
        scalability_results = self.test_scalability()
        test_results.add_scalability_results(scalability_results)

        return test_results

    def test_detection_accuracy(self) -> AccuracyResults:
        """
        æµ‹è¯•æ£€æµ‹ç²¾åº¦
        """
        # ç”ŸæˆåŒ…å«å·²çŸ¥å†²çªçš„æµ‹è¯•æ•°æ®
        test_datasets = self.test_data_generator.generate_conflict_datasets()

        accuracy_metrics = []
        for dataset in test_datasets:
            detected_conflicts = self.detector.detect_conflicts(dataset.documents)

            # è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°
            precision = self.calculate_precision(detected_conflicts, dataset.ground_truth)
            recall = self.calculate_recall(detected_conflicts, dataset.ground_truth)
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

            accuracy_metrics.append(AccuracyMetric(
                dataset_name=dataset.name,
                precision=precision,
                recall=recall,
                f1_score=f1_score
            ))

        return AccuracyResults(accuracy_metrics)
```

## ğŸ“š é…ç½®å’Œæ‰©å±•

### è‡ªå®šä¹‰å†²çªæ£€æµ‹è§„åˆ™
```yaml
# .claude/conflict-detection-rules.yml
conflict_detection_rules:
  semantic_conflicts:
    similarity_threshold: 0.7
    contradiction_patterns:
      - exclusive_actions: ["create", "delete"]
      - temporal_conflicts: ["before", "after"]
      - access_conflicts: ["public", "private"]

  business_rule_conflicts:
    max_combination_size: 5
    logic_timeout: 30  # seconds
    cyclic_dependency_detection: true

  implementation_consistency:
    api_signature_strictness: "strict"  # strict|moderate|relaxed
    data_model_validation: true
    version_compatibility_check: true

  custom_patterns:
    domain_specific_rules:
      - name: "financial_compliance"
        pattern: "audit_trail_required"
        conflict_with: ["data_anonymization"]
      - name: "security_requirements"
        pattern: "encryption_required"
        conflict_with: ["performance_optimization"]
```

### æ’ä»¶æ‰©å±•æ¥å£
```python
class ConflictDetectionPlugin:
    """
    å†²çªæ£€æµ‹æ’ä»¶åŸºç±»
    """
    def __init__(self, name: str):
        self.name = name

    def detect_conflicts(self, context: DetectionContext) -> List[Conflict]:
        """
        æ’ä»¶çš„å†²çªæ£€æµ‹å…¥å£ç‚¹
        """
        raise NotImplementedError

    def get_supported_conflict_types(self) -> List[str]:
        """
        è¿”å›æ’ä»¶æ”¯æŒçš„å†²çªç±»å‹
        """
        raise NotImplementedError

    def configure(self, config: Dict[str, Any]) -> None:
        """
        é…ç½®æ’ä»¶å‚æ•°
        """
        pass

# ç¤ºä¾‹ï¼šé¢†åŸŸç‰¹å®šçš„å†²çªæ£€æµ‹æ’ä»¶
class FinancialComplianceConflictDetector(ConflictDetectionPlugin):
    def __init__(self):
        super().__init__("financial_compliance")

    def detect_conflicts(self, context: DetectionContext) -> List[Conflict]:
        conflicts = []

        # æ£€æµ‹è´¢åŠ¡åˆè§„ç›¸å…³çš„å†²çª
        audit_requirements = self.extract_audit_requirements(context.documents)
        privacy_requirements = self.extract_privacy_requirements(context.documents)

        for audit_req in audit_requirements:
            for privacy_req in privacy_requirements:
                if self.are_conflicting_compliance_requirements(audit_req, privacy_req):
                    conflict = ComplianceConflict(
                        type="audit_privacy_conflict",
                        description=f"Audit requirement conflicts with privacy requirement",
                        audit_requirement=audit_req,
                        privacy_requirement=privacy_req,
                        severity="high"
                    )
                    conflicts.append(conflict)

        return conflicts
```

---

**æ€»ç»“**: è¿™å¥—å†²çªæ£€æµ‹ç®—æ³•ä¸º cc-devflow æä¾›äº†ä¼ä¸šçº§çš„ä¸€è‡´æ€§ä¿è¯èƒ½åŠ›ï¼Œé€šè¿‡å¤šå±‚æ¬¡ã€å¤šç»´åº¦çš„æ™ºèƒ½æ£€æµ‹ï¼Œç¡®ä¿ä»éœ€æ±‚åˆ°å®ç°çš„å…¨é“¾è·¯è´¨é‡ï¼Œæ”¯æŒå¤§è§„æ¨¡é¡¹ç›®çš„é«˜æ•ˆå¼€å‘å’Œç»´æŠ¤ã€‚
