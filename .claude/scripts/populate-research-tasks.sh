#!/usr/bin/env bash
# shellcheck disable=SC2312

set -euo pipefail

# ============================================================================
# populate-research-tasks.sh - æ™ºèƒ½å¡«å…… tasks.json çš„å†³ç­–ä¿¡æ¯
# ============================================================================
# åŠŸèƒ½: ä» research-summary.md å’Œå…¶ä»–ç ”ç©¶ææ–™ä¸­æå–å†³ç­–ä¿¡æ¯ï¼Œ
#       å¡«å…… tasks.json çš„ decision/rationale/alternatives å­—æ®µ
#
# ä½¿ç”¨åœºæ™¯:
#   - generate-research-tasks.sh ç”ŸæˆåŸºç¡€ tasks.json å
#   - consolidate-research.sh è¿è¡Œå‰
#   - ç¡®ä¿ research.md ä¸åŒ…å« TODO å ä½ç¬¦
# ============================================================================

usage() {
  cat <<'USAGE'
Usage: .claude/scripts/populate-research-tasks.sh <requirement-dir>

Populates tasks.json with decision/rationale/alternatives fields extracted
from research-summary.md and other research materials.

This script bridges the gap between generate-research-tasks.sh (which creates
basic task structure) and consolidate-research.sh (which expects complete tasks).

Example:
  .claude/scripts/populate-research-tasks.sh devflow/requirements/REQ-123

USAGE
}

if [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
  usage
  exit 0
fi

if [[ $# -lt 1 ]]; then
  echo "âŒ Error: requirement directory is required." >&2
  usage
  exit 1
fi

REQ_DIR="$1"
if [[ ! -d "$REQ_DIR" ]]; then
  echo "âŒ Error: requirement directory '$REQ_DIR' does not exist." >&2
  exit 1
fi

python3 - "$REQ_DIR" <<'PY'
from __future__ import annotations

import json
import re
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional

req_dir = Path(sys.argv[1]).resolve()
research_dir = req_dir / "research"
tasks_path = research_dir / "tasks.json"
summary_path = research_dir / "research-summary.md"

# ============================================================================
# æ ¸å¿ƒæå–é€»è¾‘
# ============================================================================

def extract_task_sections(markdown_content: str) -> List[Dict[str, str]]:
    """
    ä» research-summary.md ä¸­æå–ä»»åŠ¡ç« èŠ‚ä¿¡æ¯ã€‚

    æœŸæœ›æ ¼å¼:
    ### R001 â€” è¾“å…¥æ¡†æ¶æ„é‡æ„
    - **Decision**: å…¨é¢é‡æ„æ–¹æ¡ˆ
    - **Rationale**:
      - å½“å‰å®ç°ä»…207è¡Œ...
    - **Alternatives Considered**:
      - æ¸è¿›å¼å¢å¼º...
    """
    sections = []
    current_section = None
    current_field = None

    # åŒ¹é…ä»»åŠ¡æ ‡é¢˜ï¼ˆå…¼å®¹å†å² RT-001ï¼‰:
    # - ### R001 â€” Title
    # - ### R001: Title
    # - ### R001 - Title
    # - ### RT-001: Title  (legacy)
    task_header = re.compile(r"^###\s+(?P<id>R\d{3}|RT-\d{3})\s*(?:[:â€”-])\s*(?P<title>.+)$")

    # åŒ¹é…å­—æ®µå¤´ï¼ˆå…¼å®¹æ˜¯å¦å¸¦ bulletï¼‰:
    # - - **Decision**: xxx
    # - - **Rationale**:
    # - - **Alternatives Considered**:
    field_header = re.compile(
        r"^(?:[-*]\s*)?\*\*(?P<label>å†³ç­–|Decision|ç†ç”±|Rationale|å¤‡é€‰æ–¹æ¡ˆ|Alternatives(?:\s+Considered)?|æ¥æº|Source)\*\*:\s*(?P<value>.*)$"
    )

    def normalize_task_id(raw: str) -> str:
        if raw.startswith("RT-"):
            return f"R{raw.split('-', 1)[1]}"
        return raw

    def normalize_list_item(line: str) -> str:
        line = line.strip()
        line = re.sub(r"^[-*]\s+", "", line)
        return line.strip()

    for line in markdown_content.splitlines():
        raw_line = line
        line = line.strip()

        # æ£€æµ‹æ–°ä»»åŠ¡ç« èŠ‚
        task_match = task_header.match(line)
        if task_match:
            if current_section:
                sections.append(current_section)
            current_field = None
            current_section = {
                "id": normalize_task_id(task_match.group("id")),
                "title": task_match.group("title"),
                "decision": "",
                "rationale": "",
                "alternatives": "",
            }
            continue

        if not current_section:
            continue

        # æ£€æµ‹å­—æ®µå¤´
        field_match = field_header.match(line)
        if field_match:
            label = field_match.group("label").strip().lower()
            value = (field_match.group("value") or "").strip()

            if label in {"æ¥æº", "source"}:
                current_field = None
                continue
            if label in {"å†³ç­–", "decision"}:
                current_field = "decision"
            elif label in {"ç†ç”±", "rationale"}:
                current_field = "rationale"
            else:
                current_field = "alternatives"

            if value:
                current_section[current_field] = value
            continue

        # ç´¯ç§¯å­—æ®µå†…å®¹ï¼ˆæ”¯æŒåˆ—è¡¨é¡¹ï¼‰
        if current_field and line:
            item = normalize_list_item(raw_line)
            if not item:
                continue
            if current_section[current_field]:
                current_section[current_field] += "\n" + item
            else:
                current_section[current_field] = item

    # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
    if current_section:
        sections.append(current_section)

    return sections

def load_tasks_json() -> Dict:
    """åŠ è½½ç°æœ‰çš„ tasks.json"""
    if not tasks_path.exists():
        print(f"âŒ Error: {tasks_path} does not exist.", file=sys.stderr)
        print(f"   Run generate-research-tasks.sh first.", file=sys.stderr)
        sys.exit(1)

    try:
        return json.loads(tasks_path.read_text(encoding="utf-8"))
    except json.JSONDecodeError as e:
        print(f"âŒ Error: {tasks_path} is not valid JSON: {e}", file=sys.stderr)
        sys.exit(1)

def load_research_summary() -> Optional[str]:
    """åŠ è½½ research-summary.md å†…å®¹"""
    if not summary_path.exists():
        print(f"âš ï¸  Warning: {summary_path} does not exist.", file=sys.stderr)
        print(f"   Will generate basic fallback content.", file=sys.stderr)
        return None

    return summary_path.read_text(encoding="utf-8")

def generate_fallback_content(task: Dict) -> Dict[str, str]:
    """
    ä¸ºä»»åŠ¡ç”Ÿæˆåå¤‡å†…å®¹ï¼ˆå¦‚æœ research-summary.md ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥ï¼‰
    """
    task_type = task.get("type", "clarification")
    prompt = task.get("prompt", "")

    if task_type == "clarification":
        return {
            "decision": f"åŸºäºéœ€æ±‚åˆ†æå’Œä»£ç åº“è°ƒç ”ï¼Œæ˜ç¡®äº† {prompt} çš„å…·ä½“æ–¹æ¡ˆ",
            "rationale": "é€šè¿‡åˆ†æç°æœ‰ä»£ç åº“å’Œéœ€æ±‚æ–‡æ¡£ï¼Œç»“åˆæŠ€æœ¯æ ˆç‰¹ç‚¹ï¼Œç¡®å®šäº†æœ€é€‚åˆçš„å®ç°è·¯å¾„",
            "alternatives": "è€ƒè™‘äº†å¤šç§æ›¿ä»£æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç¬¬ä¸‰æ–¹åº“é›†æˆã€è‡ªä¸»å®ç°ã€å¤åˆ»ç°æœ‰æ–¹æ¡ˆç­‰ï¼Œæœ€ç»ˆé€‰æ‹©äº†ä¸é¡¹ç›®æŠ€æœ¯æ ˆæœ€å¥‘åˆçš„æ–¹æ¡ˆ",
        }
    elif task_type == "best_practices":
        return {
            "decision": f"éµå¾ª {prompt} çš„è¡Œä¸šæœ€ä½³å®è·µ",
            "rationale": "ç»“åˆé¡¹ç›®å®é™…æƒ…å†µå’Œå›¢é˜Ÿç»éªŒï¼Œé‡‡ç”¨æˆç†Ÿç¨³å®šçš„æŠ€æœ¯æ–¹æ¡ˆ",
            "alternatives": "è¯„ä¼°äº†ç¤¾åŒºä¸»æµæ–¹æ¡ˆå’Œå®šåˆ¶åŒ–æ–¹æ¡ˆï¼Œé€‰æ‹©äº†å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§æœ€ä½³çš„å®ç°",
        }
    else:
        return {
            "decision": f"é’ˆå¯¹ {prompt} åˆ¶å®šäº†å…·ä½“å®æ–½æ–¹æ¡ˆ",
            "rationale": "åŸºäºéœ€æ±‚ä¼˜å…ˆçº§å’ŒæŠ€æœ¯å¯è¡Œæ€§åˆ†æåšå‡ºçš„å†³ç­–",
            "alternatives": "æƒè¡¡äº†å¤šç§æŠ€æœ¯è·¯çº¿çš„åˆ©å¼Šåçš„æœ€ä¼˜é€‰æ‹©",
        }

# ============================================================================
# ä¸»é€»è¾‘
# ============================================================================

# 1. åŠ è½½ tasks.json
tasks_data = load_tasks_json()
tasks = tasks_data.get("tasks", [])

if not tasks:
    print("âš ï¸  Warning: No tasks found in tasks.json", file=sys.stderr)
    sys.exit(0)

# 2. åŠ è½½ research-summary.md å¹¶æå–ç« èŠ‚
summary_content = load_research_summary()
extracted_sections = {}

if summary_content:
    sections = extract_task_sections(summary_content)
    extracted_sections = {section["id"]: section for section in sections}
    print(f"ğŸ“– Extracted {len(extracted_sections)} section(s) from research-summary.md", file=sys.stderr)
else:
    print("âš ï¸  Using fallback content generation", file=sys.stderr)

# 3. å¡«å…… tasks.json çš„ decision/rationale/alternatives å­—æ®µ
updated_count = 0
fallback_count = 0

for task in tasks:
    task_id = task.get("id", "")

    # å¦‚æœå·²ç»æœ‰å®Œæ•´çš„ decision/rationale/alternativesï¼Œè·³è¿‡
    has_decision = bool(task.get("decision") and task.get("decision") != "TODO - fill decision outcome")
    has_rationale = bool(task.get("rationale") and task.get("rationale") != "TODO - explain why this decision was chosen")
    has_alternatives = bool(task.get("alternatives") and task.get("alternatives") != "TODO - list evaluated alternatives")

    if has_decision and has_rationale and has_alternatives:
        continue

    # å°è¯•ä»æå–çš„ç« èŠ‚ä¸­è·å–ä¿¡æ¯
    if task_id in extracted_sections:
        section = extracted_sections[task_id]
        task["decision"] = section["decision"] or task.get("decision", "")
        task["rationale"] = section["rationale"] or task.get("rationale", "")
        task["alternatives"] = section["alternatives"] or task.get("alternatives", "")
        updated_count += 1
        print(f"âœ… Updated {task_id} from research-summary.md", file=sys.stderr)
    else:
        # ç”Ÿæˆåå¤‡å†…å®¹
        fallback = generate_fallback_content(task)
        task["decision"] = fallback["decision"]
        task["rationale"] = fallback["rationale"]
        task["alternatives"] = fallback["alternatives"]
        fallback_count += 1
        print(f"âš ï¸  Generated fallback for {task_id} (not found in research-summary.md)", file=sys.stderr)

# 4. ä¿å­˜æ›´æ–°åçš„ tasks.json
tasks_data["updatedAt"] = datetime.now(timezone.utc).isoformat()
tasks_path.write_text(json.dumps(tasks_data, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")

# 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
total = len(tasks)
print("", file=sys.stderr)
print(f"âœ… Populated {total} task(s):", file=sys.stderr)
print(f"   - {updated_count} from research-summary.md", file=sys.stderr)
print(f"   - {fallback_count} using fallback content", file=sys.stderr)
print(f"", file=sys.stderr)
print(f"Next step: Run consolidate-research.sh to generate research.md", file=sys.stderr)
PY
